{
    "activation": "gelu",
    "attn_dim": 1024,
    "attn_drop": 0.0,
    "base_momentum": 0.99,
    "batch_size": 32,
    "checkpoint_freq": 10,
    "debug": false,
    "display_logging": true,
    "drop_mlp": 0.0,
    "drop_path": 0.0,
    "dropout": 0.1,
    "ema": [
        0.996,
        0.999
    ],
    "emb_dim": 128,
    "embedding_skip_connections": true,
    "encoder_depth": 3,
    "eps": 1e-07,
    "event_info_file": "",
    "hidden_features": 512,
    "in_features": 1024,
    "init_std": 0.02,
    "initial_embedding_dim": 256,
    "initial_embedding_skip_connections": false,
    "input_dim": 120,
    "learning_rate": 0.001,
    "linear_block_type": "basic",
    "log_freq": 10,
    "lr": 0.0001,
    "max_grad_norm": 1.0,
    "min_lr": 1e-06,
    "mlp_ratio": 4.0,
    "normalization": "LayerNorm",
    "num_context_subjets": 10,
    "num_embedding_layers": 10,
    "num_epochs": 2,
    "num_heads": 4,
    "num_jets": 100000,
    "num_layers": 4,
    "num_part_ftr": 4,
    "num_particles": 30,
    "num_steps_per_epoch": 3125,
    "num_subjets": 20,
    "num_val_jets": 10000,
    "num_workers": 0,
    "optimizer": "AdamW",
    "out_features": 1024,
    "pred_depth": 3,
    "predictor_emb_dim": 512,
    "proj_drop": 0.0,
    "qk_scale": null,
    "qkv_bias": true,
    "repr_dim": -1,
    "scheduler": "cosine",
    "skip_connections": true,
    "start_epochs": 0,
    "testing_file": "",
    "training_file": "",
    "use_amp": true,
    "use_predictor": true,
    "validation_file": "",
    "warmup_epochs": 10,
    "warmup_start_lr": 1e-08,
    "weight_decay": 0.01
}