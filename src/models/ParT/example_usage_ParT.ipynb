{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce5e9be-c950-43fb-88af-25f251b05e31",
   "metadata": {},
   "source": [
    "## Paper: https://arxiv.org/abs/2202.03772v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45217fe-927f-495f-b091-61c7f00267a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T03:48:28.376321Z",
     "iopub.status.busy": "2024-09-01T03:48:28.376077Z",
     "iopub.status.idle": "2024-09-01T03:48:29.446507Z",
     "shell.execute_reply": "2024-09-01T03:48:29.446151Z",
     "shell.execute_reply.started": "2024-09-01T03:48:28.376308Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# load torch modules\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71a4a58-bc8b-4665-b4dc-d2589af1eadb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T03:48:29.447322Z",
     "iopub.status.busy": "2024-09-01T03:48:29.447096Z",
     "iopub.status.idle": "2024-09-01T03:48:30.456614Z",
     "shell.execute_reply": "2024-09-01T03:48:30.456260Z",
     "shell.execute_reply.started": "2024-09-01T03:48:29.447310Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../../\")\n",
    "from models.ParT.ParticleTransformerEncoder import ParTEncoder\n",
    "from models.ParT.utils import calculate_cartesian_components, generate_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c409dff-d2d9-4c69-b51e-c2ce24855bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T03:48:30.457167Z",
     "iopub.status.busy": "2024-09-01T03:48:30.457067Z",
     "iopub.status.idle": "2024-09-01T03:48:30.760299Z",
     "shell.execute_reply": "2024-09-01T03:48:30.760012Z",
     "shell.execute_reply.started": "2024-09-01T03:48:30.457157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "if world_size:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    for i in range(world_size):\n",
    "        print(\n",
    "            f\"Device {i}: {torch.cuda.get_device_name(i)}\", flush=True\n",
    "        )\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Device: CPU\", file=logfile, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90afcdd-67ee-4287-acea-76ec66ee6136",
   "metadata": {},
   "source": [
    "# Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8892d18-8736-471f-ba3b-fdfb2919b87b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T03:48:33.509412Z",
     "iopub.status.busy": "2024-09-01T03:48:33.509162Z",
     "iopub.status.idle": "2024-09-01T03:48:33.512835Z",
     "shell.execute_reply": "2024-09-01T03:48:33.512570Z",
     "shell.execute_reply.started": "2024-09-01T03:48:33.509400Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(dataset_path, flag, n_files=-1):\n",
    "    # make another variable that combines flag and subdirectory such as 3_features_raw\n",
    "    path_id = f\"{flag}-\"\n",
    "    data_files = glob.glob(f\"{dataset_path}/{flag}/processed/6_features_raw/data/*\")\n",
    "    path_id += \"6_features\"\n",
    "\n",
    "    data = []\n",
    "    for i, _ in enumerate(data_files):\n",
    "        data.append(\n",
    "            np.load(f\"{dataset_path}/{flag}/processed/6_features_raw/data/data_{i}.npy\")\n",
    "        )\n",
    "        print(f\"--- loaded file {i} from `{path_id}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_labels(dataset_path, flag, n_files=-1):\n",
    "    data_files = glob.glob(f\"{dataset_path}/{flag}/processed/6_features_raw/labels/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        data.append(\n",
    "            np.load(\n",
    "                f\"{dataset_path}/{flag}/processed/6_features_raw/labels/labels_{i}.npy\"\n",
    "            )\n",
    "        )\n",
    "        print(f\"--- loaded label file {i} from `{flag}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98b8dd6e-7dce-41d8-978b-63d226e7af1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T04:01:12.413443Z",
     "iopub.status.busy": "2024-09-01T04:01:12.413238Z",
     "iopub.status.idle": "2024-09-01T04:01:14.087610Z",
     "shell.execute_reply": "2024-09-01T04:01:14.087153Z",
     "shell.execute_reply.started": "2024-09-01T04:01:12.413431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- loaded file 0 from `train-6_features` directory\n",
      "--- loaded label file 0 from `train` directory\n",
      "training data shape: torch.Size([10, 6, 50])\n",
      "training labels shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "data = load_data(\"/ssl-jet-vol-v3/toptagging\", \"train\", 1)\n",
    "labels = load_labels(\"/ssl-jet-vol-v3/toptagging\", \"train\", 1)\n",
    "num_jets = 10 # Do not use more than 1000, as memory usage will blow up\n",
    "tr_dat_in = torch.from_numpy(np.concatenate(data, axis=0))[:num_jets].to(device)\n",
    "tr_lab_in = torch.from_numpy(np.concatenate(labels, axis=0))[:num_jets].to(device)\n",
    "print(\"training data shape:\", tr_dat_in.shape)\n",
    "print(\"training labels shape:\", tr_lab_in.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8caecc-bc95-4bbb-9592-59173ae8a32b",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f741c08-6720-4e51-a103-34c850056e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T04:00:08.056479Z",
     "iopub.status.busy": "2024-09-01T04:00:08.056278Z",
     "iopub.status.idle": "2024-09-01T04:00:08.059518Z",
     "shell.execute_reply": "2024-09-01T04:00:08.059177Z",
     "shell.execute_reply.started": "2024-09-01T04:00:08.056468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of v: torch.Size([10, 4, 50])\n",
      "shape of mask: torch.Size([10, 1, 50])\n"
     ]
    }
   ],
   "source": [
    "v = calculate_cartesian_components(tr_dat_in).to(device)\n",
    "print(\"shape of v:\", v.shape)  # Should print (batch_size, 4, 50)\n",
    "mask = generate_mask(tr_dat_in)\n",
    "print(\"shape of mask:\", mask.shape) # Should print (batch_size, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b54ce7d0-46be-4c38-8393-ec839c05fe36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T04:00:08.690395Z",
     "iopub.status.busy": "2024-09-01T04:00:08.690189Z",
     "iopub.status.idle": "2024-09-01T04:00:08.762119Z",
     "shell.execute_reply": "2024-09-01T04:00:08.761696Z",
     "shell.execute_reply.started": "2024-09-01T04:00:08.690383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParticleTransformerEncoder(\n",
      "  (embed): Embed(\n",
      "    (input_bn): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (embed): Sequential(\n",
      "      (0): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): Linear(in_features=6, out_features=128, bias=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (4): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (5): GELU(approximate='none')\n",
      "      (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (7): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (8): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (pair_embed): PairEmbed(\n",
      "    (embed): Sequential(\n",
      "      (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): GELU(approximate='none')\n",
      "      (4): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): GELU(approximate='none')\n",
      "      (7): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): GELU(approximate='none')\n",
      "      (10): Conv1d(64, 8, kernel_size=(1,), stride=(1,))\n",
      "      (11): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-7): 8 x Block(\n",
      "      (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (act_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "shape of latent space: torch.Size([10, 128])\n"
     ]
    }
   ],
   "source": [
    "output_dim = 128\n",
    "encoder = ParTEncoder(input_dim=6, embed_dims=[128, 512, output_dim]).to(\n",
    "    device\n",
    ")  # the last embedding dimension is also the latent space dimension\n",
    "print(encoder)\n",
    "reps = encoder(tr_dat_in.to(torch.float32), v.to(torch.float32), mask)\n",
    "print(\"shape of latent space:\", reps.shape) # Should print (batch_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c79fc5-31c9-4ed6-91fe-d5b0d494162d",
   "metadata": {},
   "source": [
    "# Training ParticleTransformerEncoder with a linear classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cce82f9-f5a5-4e6a-b1a7-eeb2d6b4812f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T04:01:32.131515Z",
     "iopub.status.busy": "2024-09-01T04:01:32.131310Z",
     "iopub.status.idle": "2024-09-01T04:01:32.165069Z",
     "shell.execute_reply": "2024-09-01T04:01:32.164629Z",
     "shell.execute_reply.started": "2024-09-01T04:01:32.131504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: torch.Size([10000, 6, 50])\n",
      "training labels shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "num_jets = 10000 # Here we can use more since batch_size is small\n",
    "tr_dat_in = torch.from_numpy(np.concatenate(data, axis=0))[:num_jets].to(device)\n",
    "tr_lab_in = torch.from_numpy(np.concatenate(labels, axis=0))[:num_jets].to(device)\n",
    "print(\"training data shape:\", tr_dat_in.shape)\n",
    "print(\"training labels shape:\", tr_lab_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40bde42f-f330-4576-98f2-24e8ac22fc53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T03:56:08.439609Z",
     "iopub.status.busy": "2024-09-01T03:56:08.439402Z",
     "iopub.status.idle": "2024-09-01T03:58:16.692475Z",
     "shell.execute_reply": "2024-09-01T03:58:16.691870Z",
     "shell.execute_reply.started": "2024-09-01T03:56:08.439598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.6696202198918254\n",
      "epoch: 0, accuracy: 0.5833\n",
      "Epoch 1 loss 0.6143759173897508\n",
      "epoch: 1, accuracy: 0.672\n",
      "Epoch 2 loss 0.5357150441160599\n",
      "epoch: 2, accuracy: 0.7496\n",
      "Epoch 3 loss 0.4497538974966866\n",
      "epoch: 3, accuracy: 0.8033\n",
      "Epoch 4 loss 0.3990943685126381\n",
      "epoch: 4, accuracy: 0.8301\n",
      "Epoch 5 loss 0.37819552007384194\n",
      "epoch: 5, accuracy: 0.8429\n",
      "Epoch 6 loss 0.36639379283871515\n",
      "epoch: 6, accuracy: 0.8459\n",
      "Epoch 7 loss 0.3550738359030824\n",
      "epoch: 7, accuracy: 0.8541\n",
      "Epoch 8 loss 0.3476545858783082\n",
      "epoch: 8, accuracy: 0.8549\n",
      "Epoch 9 loss 0.3426943522529861\n",
      "epoch: 9, accuracy: 0.86\n",
      "Epoch 10 loss 0.33955272008626225\n",
      "epoch: 10, accuracy: 0.8599\n",
      "Epoch 11 loss 0.3362997557027652\n",
      "epoch: 11, accuracy: 0.8621\n",
      "Epoch 12 loss 0.3311624353210004\n",
      "epoch: 12, accuracy: 0.8643\n",
      "Epoch 13 loss 0.3287777806432864\n",
      "epoch: 13, accuracy: 0.8627\n",
      "Epoch 14 loss 0.3252396984888723\n",
      "epoch: 14, accuracy: 0.8648\n",
      "Epoch 15 loss 0.32175163988964245\n",
      "epoch: 15, accuracy: 0.8675\n",
      "Epoch 16 loss 0.31911054448769116\n",
      "epoch: 16, accuracy: 0.8706\n",
      "Epoch 17 loss 0.32127755694686416\n",
      "epoch: 17, accuracy: 0.8671\n",
      "Epoch 18 loss 0.3159944831182401\n",
      "epoch: 18, accuracy: 0.8722\n",
      "Epoch 19 loss 0.31208380064168295\n",
      "epoch: 19, accuracy: 0.8722\n",
      "Epoch 20 loss 0.31195165807256303\n",
      "epoch: 20, accuracy: 0.8714\n",
      "Epoch 21 loss 0.31117555282462517\n",
      "epoch: 21, accuracy: 0.8706\n",
      "Epoch 22 loss 0.30899613790999586\n",
      "epoch: 22, accuracy: 0.8721\n",
      "Epoch 23 loss 0.30725909493411313\n",
      "epoch: 23, accuracy: 0.8739\n",
      "Epoch 24 loss 0.3066898859061372\n",
      "epoch: 24, accuracy: 0.8739\n",
      "Epoch 25 loss 0.30424449909418916\n",
      "epoch: 25, accuracy: 0.8756\n",
      "Epoch 26 loss 0.3032080853661409\n",
      "epoch: 26, accuracy: 0.8762\n",
      "Epoch 27 loss 0.2994471584408047\n",
      "epoch: 27, accuracy: 0.8777\n",
      "Epoch 28 loss 0.3000910462329563\n",
      "epoch: 28, accuracy: 0.8775\n",
      "Epoch 29 loss 0.2974535034249385\n",
      "epoch: 29, accuracy: 0.8781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def Projector(mlp, embedding):\n",
    "    mlp_spec = f\"{embedding}-{mlp}\"\n",
    "    layers = []\n",
    "    f = list(map(int, mlp_spec.split(\"-\")))\n",
    "    for i in range(len(f) - 2):\n",
    "        layers.append(nn.Linear(f[i], f[i + 1]))\n",
    "        layers.append(nn.BatchNorm1d(f[i + 1]))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(f[-2], f[-1], bias=False))\n",
    "    return nn.Sequential(*layers)\n",
    "proj = Projector(2, output_dim)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "            [{\"params\": proj.parameters()}, {\"params\": encoder.parameters(), \"lr\": 1e-6}],\n",
    "            lr=1e-4,\n",
    "        )\n",
    "proj.to(device)\n",
    "encoder.to(device)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "indices_list = torch.split(torch.randperm(tr_dat_in.shape[0]), 32)\n",
    "encoder.train()\n",
    "proj.train()\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    loss_e = []\n",
    "    predicted_e, correct_e = [], []\n",
    "    for i, indices in enumerate(indices_list):\n",
    "        optimizer.zero_grad()\n",
    "        x = tr_dat_in[indices, :, :].to(device)\n",
    "        v = calculate_cartesian_components(x).to(device)\n",
    "        mask = generate_mask(x)\n",
    "        y = tr_lab_in[indices]\n",
    "        y = torch.Tensor(y).to(device)\n",
    "        reps = encoder(x.to(torch.float32), v.to(torch.float32), mask)\n",
    "        out = proj(reps)\n",
    "        batch_loss = loss(out, y.long()).to(device)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss = batch_loss.detach().cpu().item()\n",
    "        # print(batch_loss)\n",
    "        loss_e.append(batch_loss)\n",
    "        predicted_e.append(softmax(out).cpu().data.numpy())\n",
    "        correct_e.append(y.cpu().data)\n",
    "    print(f\"Epoch {epoch} loss {np.mean(loss_e)}\")\n",
    "    predicted = np.concatenate(predicted_e)\n",
    "    target = np.concatenate(correct_e)\n",
    "\n",
    "    # get the accuracy\n",
    "    accuracy = accuracy_score(target, predicted[:, 1] > 0.5)\n",
    "    print(\n",
    "        \"epoch: \" + str(epoch) + \", accuracy: \" + str(round(accuracy, 5)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad275a7-3dc7-4331-b233-a72b26f76ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
